{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "waWXlprixk7c"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from skimage import io\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import gradio as gr\n",
        "from tensorflow.keras.models import load_model\n",
        "from skimage.measure import label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "eGl7J4ewKypf",
        "outputId": "b92d5f91-5af8-4583-a712-89004fbf22dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Segmented masks saved in /content/results\n"
          ]
        }
      ],
      "source": [
        "# Paths\n",
        "input_dir = \"/content/train/images/\"  # Directory with original images\n",
        "output_dir = \"/content/results\"  # Directory where segmented masks will be saved\n",
        "\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "# Function to segment an image (you can modify this function to use other segmentation methods)\n",
        "def segment_image(image):\n",
        "    # Convert to grayscale\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Apply threshold to create a binary mask\n",
        "    _, binary_mask = cv2.threshold(gray, 128, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    return binary_mask\n",
        "\n",
        "# Loop over all images in the input directory\n",
        "for image_name in os.listdir(input_dir):\n",
        "    image_path = os.path.join(input_dir, image_name)\n",
        "\n",
        "    # Read the image\n",
        "    image = io.imread(image_path)\n",
        "\n",
        "    # Segment the image\n",
        "    segmented_mask = segment_image(image)\n",
        "\n",
        "    # Save the segmented mask\n",
        "    output_path = os.path.join(output_dir, image_name)\n",
        "    cv2.imwrite(output_path, segmented_mask)\n",
        "print(f\"Segmented masks saved in {output_dir}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nbk7l2wUKyuG",
        "outputId": "f6948a42-72ab-4143-8bd6-1c7b6850dfd2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "315/315 [==============================] - 1539s 5s/step - loss: 0.1234 - accuracy: 0.9350 - val_loss: 0.0536 - val_accuracy: 0.9587\n",
            "Model training complete.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "# Paths\n",
        "train_images_dir = '/content/train/images/'\n",
        "train_masks_dir = '/content/results/'\n",
        "\n",
        "# Function to load images and masks, and resize them to the desired shape\n",
        "def load_images_and_masks(image_dir, mask_dir, target_size=(256, 256)):\n",
        "    images = []\n",
        "    masks = []\n",
        "\n",
        "    for image_name in os.listdir(image_dir):\n",
        "        image_path = os.path.join(image_dir, image_name)\n",
        "        mask_path = os.path.join(mask_dir, image_name)\n",
        "\n",
        "        # Load image and mask\n",
        "        image = cv2.imread(image_path)\n",
        "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        # Resize the image and mask to the target size\n",
        "        image = cv2.resize(image, target_size)\n",
        "        mask = cv2.resize(mask, target_size)\n",
        "\n",
        "        # Normalize images and masks\n",
        "        image = image / 255.0\n",
        "        mask = mask / 255.0\n",
        "\n",
        "        images.append(image)\n",
        "        masks.append(mask)\n",
        "\n",
        "    return np.array(images), np.array(masks)\n",
        "\n",
        "# Load training data with resized images\n",
        "X_train, y_train = load_images_and_masks(train_images_dir, train_masks_dir, target_size=(256, 256))\n",
        "\n",
        "# Expand dimensions of masks to match the expected shape of the model (batch, height, width, channels)\n",
        "y_train = np.expand_dims(y_train, axis=-1)\n",
        "\n",
        "# U-Net architecture\n",
        "def unet_model(input_shape):\n",
        "    inputs = layers.Input(input_shape)\n",
        "\n",
        "    # Encoder\n",
        "    c1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    c1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c1)\n",
        "    p1 = layers.MaxPooling2D((2, 2))(c1)\n",
        "\n",
        "    c2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(p1)\n",
        "    c2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c2)\n",
        "    p2 = layers.MaxPooling2D((2, 2))(c2)\n",
        "\n",
        "    # Bottleneck\n",
        "    b = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(p2)\n",
        "    b = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(b)\n",
        "\n",
        "    # Decoder\n",
        "    u1 = layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(b)\n",
        "    u1 = layers.concatenate([u1, c2])\n",
        "    c3 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(u1)\n",
        "    c3 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c3)\n",
        "\n",
        "    u2 = layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c3)\n",
        "    u2 = layers.concatenate([u2, c1])\n",
        "    c4 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(u2)\n",
        "    c4 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c4)\n",
        "\n",
        "    outputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(c4)\n",
        "\n",
        "    model = models.Model(inputs=[inputs], outputs=[outputs])\n",
        "    return model\n",
        "\n",
        "# Create the model\n",
        "input_shape = (256, 256, 3)  # Adjust based on your image dimensions\n",
        "model = unet_model(input_shape)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, batch_size=16, epochs=1, validation_split=0.1)\n",
        "\n",
        "# Save the trained model\n",
        "model.save('/content/unet_model.h5')\n",
        "\n",
        "print(\"Model training complete.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 686
        },
        "id": "ruPv1y3BKywc",
        "outputId": "67702310-3ccb-4e38-c7ec-937b2ae6b514"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://512acf1f52a07a4e25.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://512acf1f52a07a4e25.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 204ms/step\n",
            "1/1 [==============================] - 0s 89ms/step\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://512acf1f52a07a4e25.gradio.live\n"
          ]
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load the pre-trained U-Net model\n",
        "model = load_model('/content/unet_model.h5')\n",
        "\n",
        "# Function to preprocess the input image\n",
        "def preprocess_image(image, target_size=(256, 256)):\n",
        "    image = cv2.resize(image, target_size)\n",
        "    image = image / 255.0  # Normalize\n",
        "    return np.expand_dims(image, axis=0)  # Add batch dimension\n",
        "\n",
        "# Function to post-process and count buildings\n",
        "def postprocess_and_count(mask):\n",
        "    # Threshold the mask to create a binary image\n",
        "    binary_mask = mask > 0.5\n",
        "\n",
        "    # Label connected regions (buildings)\n",
        "    labeled_mask, num_buildings = label(binary_mask, return_num=True)\n",
        "\n",
        "    return labeled_mask, num_buildings\n",
        "\n",
        "# Function to detect buildings in an image and return the count\n",
        "def detect_buildings(image):\n",
        "    # Preprocess the image for the model\n",
        "    input_image = preprocess_image(image)\n",
        "\n",
        "    # Predict the mask using the model\n",
        "    predicted_mask = model.predict(input_image)[0, :, :, 0]\n",
        "\n",
        "    # Post-process the mask and count the buildings\n",
        "    labeled_mask, num_buildings = postprocess_and_count(predicted_mask)\n",
        "\n",
        "    # Convert labeled mask back to RGB for visualization\n",
        "    labeled_mask_rgb = cv2.cvtColor((labeled_mask > 0).astype(np.uint8) * 255, cv2.COLOR_GRAY2RGB)\n",
        "\n",
        "    return labeled_mask_rgb, f\"Number of buildings detected: {num_buildings}\"\n",
        "\n",
        "# Gradio interface\n",
        "gr_interface = gr.Interface(\n",
        "    fn=detect_buildings,\n",
        "    inputs=gr.Image(type=\"numpy\"),\n",
        "    outputs=[gr.Image(type=\"numpy\", label=\"Building Segmentation\"), gr.Textbox(label=\"Building Count\")],\n",
        "    title=\"Building Detection and Counting\",\n",
        "    description=\"Upload a satellite image to detect and count buildings.\",\n",
        ")\n",
        "\n",
        "# Launch the Gradio interface\n",
        "gr_interface.launch(share=True, show_error=True, debug=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_cBS2v-N0onG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_o9Bz5A_0opb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import gradio as gr\n",
        "from tensorflow.keras.models import load_model\n",
        "from skimage.measure import label, regionprops\n",
        "\n",
        "# Load the pre-trained U-Net model\n",
        "model = load_model('/content/unet_model.h5')\n",
        "\n",
        "# Function to preprocess the input image\n",
        "def preprocess_image(image, target_size=(256, 256)):\n",
        "    image = cv2.resize(image, target_size)\n",
        "    image = image / 255.0  # Normalize\n",
        "    return np.expand_dims(image, axis=0)  # Add batch dimension\n",
        "\n",
        "# Function to estimate population based on building count\n",
        "def estimate_population(building_count, people_per_building=5):\n",
        "    return building_count * people_per_building\n",
        "\n",
        "# Function to post-process and count buildings\n",
        "def postprocess_and_count(mask):\n",
        "    # Threshold the mask to create a binary image\n",
        "    binary_mask = mask > 0.5\n",
        "\n",
        "    # Label connected regions (buildings)\n",
        "    labeled_mask, num_buildings = label(binary_mask, return_num=True)\n",
        "\n",
        "    return labeled_mask, num_buildings\n",
        "\n",
        "# Function to draw boundaries around detected buildings\n",
        "def draw_building_boundaries(image, labeled_mask):\n",
        "    contours, _ = cv2.findContours((labeled_mask > 0).astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    outlined_image = cv2.drawContours(image.copy(), contours, -1, (0, 255, 0), 2)\n",
        "    return outlined_image\n",
        "\n",
        "# Function to detect buildings, estimate population, and draw boundaries\n",
        "def detect_buildings(image):\n",
        "    # Preprocess the image for the model\n",
        "    input_image = preprocess_image(image)\n",
        "\n",
        "    # Predict the mask using the model\n",
        "    predicted_mask = model.predict(input_image)[0, :, :, 0]\n",
        "\n",
        "    # Post-process the mask and count the buildings\n",
        "    labeled_mask, num_buildings = postprocess_and_count(predicted_mask)\n",
        "\n",
        "    # Estimate the population based on building count\n",
        "    estimated_population = estimate_population(num_buildings)\n",
        "\n",
        "    # Draw boundaries around detected buildings\n",
        "    outlined_image = draw_building_boundaries(cv2.resize(image, (256, 256)), labeled_mask)\n",
        "\n",
        "    # Convert labeled mask back to RGB for visualization\n",
        "    labeled_mask_rgb = cv2.cvtColor((labeled_mask > 0).astype(np.uint8) * 255, cv2.COLOR_GRAY2RGB)\n",
        "\n",
        "    return outlined_image, f\"Number of buildings detected: {num_buildings}\", f\"Estimated population: {estimated_population}\"\n",
        "\n",
        "# Gradio interface\n",
        "gr_interface = gr.Interface(\n",
        "    fn=detect_buildings,\n",
        "    inputs=gr.Image(type=\"numpy\"),\n",
        "    outputs=[\n",
        "        gr.Image(type=\"numpy\", label=\"Building Segmentation with Boundaries\"),\n",
        "        gr.Textbox(label=\"Building Count\"),\n",
        "        gr.Textbox(label=\"Estimated Population\")\n",
        "    ],\n",
        "    title=\"Building Detection, Counting, and Population Estimation\",\n",
        "    description=\"Upload a satellite image to detect, count buildings, and estimate population based on building count.\",\n",
        ")\n",
        "\n",
        "# Launch the Gradio interface\n",
        "gr_interface.launch(share=True, show_error=True, debug=True)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
